# ğŸ§  NeuroVibe  
### Feel the Conversation.

NeuroVibe is an AI-powered accessibility application that converts real-time speech into intelligent haptic (vibration) patterns, enabling deaf and hard-of-hearing users to *feel* conversations instead of hearing them.

Built for a Google AI Hackathon, NeuroVibe explores how artificial intelligence and haptics can create an alternative communication layer using touch.

---

## ğŸš€ Problem Statement

Traditional voice communication is inaccessible to deaf and hard-of-hearing individuals. While text-based solutions exist, they often fail in real-time, emotional, or urgent conversations.

There is a lack of solutions that:
- Work in real time  
- Preserve speech intensity and emotion  
- Do not rely solely on text  

---

## ğŸ’¡ Our Solution

NeuroVibe translates live speech into a tactile language using AI-driven audio analysis and haptic feedback.

Instead of playing audio on the receiverâ€™s device, NeuroVibe converts speech features such as loudness, emphasis, and emotion into vibration patterns that users can feel instantly.

---

## ğŸ” How It Works

1. **Sender speaks** using push-to-talk mode  
2. Speech is captured and streamed in real time  
3. AI analyzes speech features (intensity, pauses, emotion)  
4. Speech features are encoded into haptic signals  
5. Receiverâ€™s device vibrates dynamically based on speech patterns  

No phone numbers. No calling charges. Just real-time voice-to-touch communication.

---

## ğŸ¤– AI Integration

NeuroVibe uses AI to intelligently interpret speech instead of applying fixed vibration rules.

### AI Capabilities:
- Speech feature extraction (energy, rhythm, emphasis)
- Emotion-aware vibration mapping
- Adaptive haptic patterns for better perception

### Google AI / Cloud Tools Used:
- Google ML Kit (on-device audio processing)
- Google Speech-to-Text (optional for demo & analysis)
- Google Cloud / Firebase (backend & session management)

---

## ğŸ§© Tech Stack

### Mobile App
- React Native (Android)
- Native Vibration / Haptic APIs

### Backend
- FastAPI (Python)
- WebSockets for real-time communication

### AI / ML
- Google ML Kit
- Lightweight ML models for speech feature mapping

### Deployment
- Cloud-hosted backend (public live link for demo)

---

## ğŸ” Session & Connectivity

Instead of phone numbers, NeuroVibe uses:
- Secure session / room codes
- Optional QR-based pairing

This ensures privacy and fast connection during conversations.

---

## ğŸ¥ Demo

A 3-minute demo video is included showing:
- Session creation
- Live speech input
- Real-time haptic feedback on receiver device
- AI-driven vibration changes based on speech intensity

---

## ğŸŒ Impact

NeuroVibe aims to:
- Improve accessibility for deaf and hard-of-hearing users
- Enable silent communication in noisy environments
- Explore haptics as a new language for human interaction

---

## ğŸ“Œ Future Scope

- Wearable haptic bands for improved sensitivity
- Personalized haptic learning modes
- Full speech-to-haptic language training
- Emergency & assistive communication use cases

---

## ğŸ‘¥ Team

Built with â¤ï¸ for accessibility and inclusion.

---

## ğŸ Conclusion

NeuroVibe demonstrates how AI and haptics can bridge the gap between sound and touch, creating a new inclusive communication experience where **silence can be felt**.
